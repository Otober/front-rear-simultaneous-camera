package com.ananth.frontrearcamera.fragment

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import android.graphics.*
import android.hardware.camera2.*
import android.icu.text.SimpleDateFormat
import android.location.Location
import android.media.Image
import android.media.ImageReader
import android.os.Build
import android.os.Bundle
import android.os.Environment
import android.os.Handler
import android.os.HandlerThread
import android.util.Log
import android.util.Size
import android.util.SparseIntArray
import android.view.*
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.fragment.app.Fragment
import com.ananth.frontrearcamera.R
import com.ananth.frontrearcamera.util.CompareSizesByViewAspectRatio
import com.ananth.frontrearcamera.view.AutoFitTextureView
import com.ananth.frontrearcamera.view.ErrorDialog
import com.google.android.gms.location.FusedLocationProviderClient
import com.google.android.gms.location.LocationRequest
import com.google.android.gms.location.LocationServices
import okhttp3.*
import okhttp3.RequestBody.Companion.asRequestBody
import java.io.File
import java.io.FileOutputStream
import java.io.FileWriter
import java.io.IOException
import java.util.*
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit
import java.util.zip.ZipEntry
import java.io.BufferedOutputStream
import java.util.zip.ZipOutputStream
import java.io.FileInputStream
/**
 * A simple [Fragment] subclass.
 */

class CameraFragment : Fragment() {
    /**
     * An additional thread for running tasks that shouldn't block the UI.
     */
    private var backgroundThreadFront: HandlerThread? = null

    /**
     * An additional thread for running tasks that shouldn't block the UI.
     */
    private var backgroundThreadRear: HandlerThread? = null

    /**
     * A [Handler] for running tasks in the background.
     */
    private var backgroundHandlerFront: Handler? = null

    /**
     * A [Handler] for running tasks in the background.
     */
    private var backgroundHandlerRear: Handler? = null

    /**
     * An [ImageReader] that handles still image capture.
     */
    private var imageReaderFront: ImageReader? = null

    /**
     * An [ImageReader] that handles still image capture.
     */
    private var imageReaderRear: ImageReader? = null

    /**
     * An [AutoFitTextureView] to show the camera preview from front camera.
     */
    private lateinit var textureViewFront: AutoFitTextureView

    /**
     * An [AutoFitTextureView] to show the camera preview from rear camera.
     */
    private lateinit var textureViewRear: AutoFitTextureView

    /**
     * A [CameraCaptureSession] for camera preview.
     */
    private var captureSessionFront: CameraCaptureSession? = null

    /**
     * A [CameraCaptureSession] for camera preview.
     */
    private var captureSessionRear: CameraCaptureSession? = null

    /**
     * A reference to the opened [CameraDevice].
     */
    private var cameraDeviceFront: CameraDevice? = null

    /**
     * A reference to the opened [CameraDevice].
     */
    private var cameraDeviceRear: CameraDevice? = null

    /**
     * The [android.util.Size] of camera preview.
     */
    private lateinit var previewSizeFront: Size

    /**
     * The [android.util.Size] of camera preview.
     */
    private lateinit var previewSizeRear: Size

    /**
     * ID of the current [CameraDevice].
     */
    private lateinit var cameraIdFront: String

    /**
     * ID of the current [CameraDevice].
     */
    private lateinit var cameraIdRear: String

    /**
     * Orientation of the camera sensor
     */
    private var sensorOrientationFront = 0

    /**
     * Orientation of the camera sensor
     */
    private var sensorOrientationRear = 0

    /**
     * A [Semaphore] to prevent the app from exiting before closing the camera.
     */
    private val cameraOpenCloseLockFront = Semaphore(1)

    /**
     * A [Semaphore] to prevent the app from exiting before closing the camera.
     */
    private val cameraOpenCloseLockRear = Semaphore(1)

    /**
     * [CaptureRequest.Builder] for the camera preview
     */
    private lateinit var previewRequestBuilderFront: CaptureRequest.Builder

    /**
     * [CaptureRequest.Builder] for the camera preview
     */
    private lateinit var previewRequestBuilderRear: CaptureRequest.Builder
    /**
     * Whether the current camera device supports Flash or not.
     */
    private var flashSupported = false

    /**
     * [CaptureRequest] generated by [.previewRequestBuilder]
     */
    private lateinit var previewRequestFront: CaptureRequest

    /**
     * [CaptureRequest] generated by [.previewRequestBuilder]
     */
    private lateinit var previewRequestRear: CaptureRequest

    private var imageFront : Image? = null

    private var imageRear : Image? = null

    private var bitmapFront : Bitmap? = null

    private var bitmapRear: Bitmap? = null

    private var key1 : Bitmap? = null

    private var key2 : Bitmap? = null

    private var original_key : Bitmap? = null

    private val Frame = 1000

    private var index = 0

    private var start_time = SimpleDateFormat("yyyy-MM-dd HH:mm:ss", Locale.getDefault()).format(Date())

    private val MULTIPLE_PERMISSIONS_REQUEST_CODE = 1

    private lateinit var fusedLocationClient: FusedLocationProviderClient
    private val locationRequest: LocationRequest = LocationRequest.create().apply {
        interval = 10000 // 위치 정보 업데이트 간격
        fastestInterval = 5000 // 가장 빠른 위치 정보 업데이트 간격
        priority = LocationRequest.PRIORITY_HIGH_ACCURACY // 높은 정확도
    }

    private fun createLocationFile(): File? {

        val locationFile = File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS), "Test/location_updates.txt")
        if (!locationFile.exists()) {
            try {
                locationFile.createNewFile()
            } catch (e: IOException) {
                e.printStackTrace()
                return null
            }
        }
        return locationFile
    }

    private fun writeLocationToFile(location: Location) {
        val locationFile = createLocationFile() ?: return

        // 현재 시간을 "yyyy-MM-dd HH:mm:ss" 포맷으로 변환
        val currentTime = SimpleDateFormat("yyyy-MM-dd HH:mm:ss", Locale.getDefault()).format(Date())

        try {
            FileWriter(locationFile, true).use { writer ->
                val locationString =
                    "Start Time: $start_time \n" +
                            "End Time: $currentTime\n" +
                            "Latitude: ${location.latitude} \n" +
                            "Longitude: ${location.longitude}\n"
                writer.write(locationString) // 파일 끝에 현재 위치와 시간을 추가합니다.
                start_time = currentTime
            }
        } catch (e: IOException) {
            e.printStackTrace()
        }
    }
    fun getCurrentLocation() {
        Log.e(TAG, "getCurrentLocation")
        // 위치 권한 확인
        if (ActivityCompat.checkSelfPermission(
                requireContext(),
                Manifest.permission.ACCESS_FINE_LOCATION
            ) != PackageManager.PERMISSION_GRANTED && ActivityCompat.checkSelfPermission(
                requireContext(),
                Manifest.permission.ACCESS_COARSE_LOCATION
            ) != PackageManager.PERMISSION_GRANTED
        ) {
            // TODO: Consider calling
            // ActivityCompat#requestPermissions
            // 여기에서 누락된 권한을 요청하고, 사용자가 권한을 부여하는 경우를 처리하도록
            // onRequestPermissionsResult를 재정의하십시오.
            return
        }
        // 현재 위치를 가져오고 파일에 쓰기
        fusedLocationClient.getCurrentLocation(LocationRequest.PRIORITY_HIGH_ACCURACY, null)
            .addOnSuccessListener { location: Location? ->
                // 위치 정보가 있을 때만 작업을 수행합니다.
                if (location != null) {
                    // 위치 정보를 파일에 기록합니다.
                    writeLocationToFile(location)

                    // 파일 쓰기 작업이 완료된 것으로 가정하고 업로드를 진행합니다.
                    // 업로드는 메인 스레드에서 호출되지 않도록 해야 합니다.
                    createLocationFile()?.let { uploadFile(it) }
                }
            }

        return
    }

    fun createRandomBitmap(width: Int, height: Int): Bitmap {
        val random = Random()
        val randomBitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888)

        for (x in 0 until width) {
            for (y in 0 until height) {
                val red = random.nextInt(256)
                val green = random.nextInt(256)
                val blue = random.nextInt(256)

                randomBitmap.setPixel(x, y, Color.rgb(red, green, blue))
            }
        }
        val pixel = randomBitmap.getPixel(0, 0)
        val red = Color.red(pixel)
        val blue = Color.blue(pixel)
        val green = Color.green(pixel)
        Log.d(TAG, "random color : ${red}, ${blue}, ${green}")
        Log.d(TAG,"generate resultBitmap")
        return randomBitmap
    }


    fun xorBitmaps(bitmap1: Bitmap, bitmap2: Bitmap): Bitmap? {
        if (bitmap1.width != bitmap2.width || bitmap1.height != bitmap2.height) {
            return null // 또는 다른 방식으로 크기 불일치를 처리
        }

        val resultBitmap = Bitmap.createBitmap(bitmap1.width, bitmap1.height, bitmap1.config)

        for (x in 0 until bitmap1.width) {
            for (y in 0 until bitmap1.height) {
                val pixel1 = bitmap1.getPixel(x, y)
                val pixel2 = bitmap2.getPixel(x, y)
                val red = Color.red(pixel1) xor Color.red(pixel2)
                val green = Color.green(pixel1) xor Color.green(pixel2)
                val blue = Color.blue(pixel1) xor Color.blue(pixel2)

                resultBitmap.setPixel(x, y, Color.rgb(red, green, blue))
            }
        }
        Log.d(TAG, "XOR SUCCESS")
        return resultBitmap
    }

    fun uploadFile(file: File) {
        Log.d(TAG, "Try connect and upload file")
        val client = OkHttpClient()

        // 파일 타입을 구분하지 않고 'file' 키를 사용합니다.
        val requestBody: RequestBody = MultipartBody.Builder()
            .setType(MultipartBody.FORM)
            .addFormDataPart("file", file.name, file.asRequestBody())
            .build()

        // 요청 구성
        val request: Request = Request.Builder()
            .url("http://192.168.161.24:3000/upload")
            .post(requestBody)
            .build()

        // 별도의 스레드에서 실행
        Thread {
            try {
                client.newCall(request).execute().use { response ->
                    if (!response.isSuccessful) throw IOException("Unexpected code $response")
                    Log.d(TAG, "File uploaded successfully")
                    println(response.body!!.string())
                    /*
                    if (file.exists()) {
                        val deleted = file.delete()
                        if (deleted) {
                            Log.d(TAG, "File ${file.name} deleted successfully")
                        } else {
                            Log.e(TAG, "Failed to delete file ${file.name}")
                        }
                    }*/
                }
            } catch (e: IOException) {
                // 연결 실패 또는 다른 네트워크 문제로 인한 예외 처리
                e.printStackTrace()
                Log.d(TAG, "Connect error")
                // 필요한 경우 여기에서 사용자에게 오류 상황을 알릴 수 있습니다.
            }
        }.start()
    }

    fun ImageToBitmap(image: Image): Bitmap? {
        val buffer = image.planes[0].buffer
        val bytes = ByteArray(buffer.remaining())
        buffer.get(bytes)

        return BitmapFactory.decodeByteArray(bytes, 0, bytes.size)
    }

    fun saveBitmapToFile(bitmap: Bitmap, filename: String): File {
        val out: FileOutputStream
        val dir = File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS), "Test")
        if (!dir.exists()) {
            dir.mkdirs()
        }
        val file = File(dir, filename)
        out = FileOutputStream(file)
        bitmap.compress(Bitmap.CompressFormat.PNG, 100, out) // JPEG 대신 PNG 포맷을 사용합니다.
        out.flush()
        out.close()
        return file
    }


    fun compressAndDeleteFilesByRange(tempDir: File, basePattern: String, startRange: Int, endRange: Int, zipFileName: String) {
        Thread{
            val zipFile = File(tempDir, zipFileName)
            val buffer = ByteArray(1024)
            ZipOutputStream(BufferedOutputStream(FileOutputStream(zipFile))).use { zos ->
                tempDir.listFiles { _, name ->
                    name.matches("$basePattern\\d{3}.png".toRegex()) &&
                            name.substringAfterLast("$basePattern").substringBefore(".png").toIntOrNull()?.let {
                                it in startRange..endRange
                            } ?: false
                }?.forEach { file ->
                    FileInputStream(file).use { fis ->
                        zos.putNextEntry(ZipEntry(file.name))
                        var length: Int
                        while (fis.read(buffer).also { length = it } > 0) {
                            zos.write(buffer, 0, length)
                        }
                        zos.closeEntry()

                        // 압축 후 파일 삭제
                        //file.delete()
                    }
                }
            }
            uploadFile(zipFile)
        }.start()
    }

    private fun test_imagetovideo() {

        if(index % Frame == 0) {
            Log.d(TAG, "bitmapBuffer  > $Frame")
            val dir: File = File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS), "Test")
            val tempDir = File(dir, "temp_images")
            if(index == Frame) {
                Log.d(TAG, "test_imagetovideo < 100")
                compressAndDeleteFilesByRange(tempDir, "1_frame_", 0, Frame - 1, "imageBuffer1.zip")
                compressAndDeleteFilesByRange(tempDir, "2_frame_", 0, Frame  - 1, "imageBuffer2.zip")
                index = 0
            }
            else {
                Log.d(TAG, "test_imagetovideo < 200")
                compressAndDeleteFilesByRange(tempDir, "1_frame_", Frame, 2 * Frame - 1, "imageBuffer1.zip")
                compressAndDeleteFilesByRange(tempDir, "2_frame_", Frame, 2 * Frame - 1, "imageBuffer2.zip")
                index = 0
            }

            val keyFile = original_key?.let { saveBitmapToFile(it, "key.png") }
            if (keyFile != null) {
                uploadFile(keyFile)
            }
            Log.e(TAG, "Try to make Location File")
            val location = getCurrentLocation()
        }
    }

    /**
     * This a callback object for the [ImageReader]. "onImageAvailable" will be called when a
     * still image is ready to be saved.
     */
    private val onImageAvailableListenerFront = ImageReader.OnImageAvailableListener { reader ->
        imageFront = reader.acquireLatestImage()

        imageFront?.let {
            bitmapFront = ImageToBitmap(it)
            it.close()

            bitmapRear?.let { rearBitmap ->
                var temp1 = bitmapFront!!.copy(bitmapFront!!.config, true)
                var temp2 = bitmapRear!!.copy(bitmapRear!!.config, true)


                Log.d(TAG, "in copy")
                if(index == 0) {
                    Log.d(TAG, "create Random key connect")
                    original_key = createRandomBitmap(temp1!!.width, temp1!!.height)
                    key1 = original_key!!.copy(original_key!!.config, true)
                    key2 = original_key!!.copy(original_key!!.config, true)
                }

                Log.d(TAG, "xor")

                var temp = xorBitmaps(temp1!!, key2!!)
                temp1 = temp!!.copy(temp!!.config, true)
                temp.recycle()

                Log.d(TAG, "xor temp2")
                temp = xorBitmaps(temp2!!, key1!!)
                temp2 = temp!!.copy(temp!!.config, true)
                temp.recycle()



                Log.d(TAG, "copy buffered")
                val maindir = File(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS), "Test")
                val tempDir = File(maindir, "temp_images")
                if (!tempDir.exists()) {
                    tempDir.mkdirs()
                }
                val fileName = String.format("frame_%03d.png", index)
                saveBitmapToFile(temp1, "/temp_images/1_$fileName")
                saveBitmapToFile(temp2, "/temp_images/2_$fileName")
                index += 1

                if(index % 100 == 0) {
                    Log.d(TAG, "index : ${index}")
                }

                Log.d(TAG, "copy temp to key")
                key1 = temp1!!.copy(temp1!!.config, true)
                key2 = temp2!!.copy(temp2!!.config, true)

                Log.d(TAG, "checked upload")
                test_imagetovideo()
                bitmapFront = null
                bitmapRear = null
            }
            Log.d(TAG, "onImageAvailableListenerFront Called")
        } ?: Log.e(TAG, "No image available from front reader!")
    }


    /**
     * This a callback object for the [ImageReader]. "onImageAvailable" will be called when a
     * still image is ready to be saved.
     */
    private val onImageAvailableListenerRear = ImageReader.OnImageAvailableListener { reader ->
        imageRear = reader.acquireLatestImage()
        imageRear?.let {
            bitmapRear = ImageToBitmap(it)
            it.close()
            Log.d(TAG, "onImageAvailableListenerRear Called")
        } ?: Log.e(TAG, "No image available from rear reader!")
    }



    /**
     * A [CameraCaptureSession.CaptureCallback] that handles events related to JPEG capture.
     */
    private val captureCallback = object : CameraCaptureSession.CaptureCallback() {

        private fun process(result: CaptureResult) {

        }

        private fun capturePicture(result: CaptureResult) {

        }

        override fun onCaptureProgressed(session: CameraCaptureSession,
                                         request: CaptureRequest,
                                         partialResult: CaptureResult) {
            process(partialResult)
        }

        override fun onCaptureCompleted(session: CameraCaptureSession,
                                        request: CaptureRequest,
                                        result: TotalCaptureResult) {
            process(result)
        }

    }


    /**
     * [TextureView.SurfaceTextureListener] handles several lifecycle events on the front camera's
     * [TextureView].
     */
    private val surfaceTextureListenerFront = object : TextureView.SurfaceTextureListener {

        override fun onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int) {
            openCameraFront(width, height)
        }

        override fun onSurfaceTextureSizeChanged(texture: SurfaceTexture, width: Int, height: Int) {
            configureTransformFront(width, height)
        }

        override fun onSurfaceTextureDestroyed(texture: SurfaceTexture) = true

        override fun onSurfaceTextureUpdated(texture: SurfaceTexture) = Unit

    }

    /**
     * [TextureView.SurfaceTextureListener] handles several lifecycle events on the rear camera's
     * [TextureView].
     */
    private val surfaceTextureListenerRear = object : TextureView.SurfaceTextureListener {

        override fun onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int) {
            openCameraRear(width, height)
        }

        override fun onSurfaceTextureSizeChanged(texture: SurfaceTexture, width: Int, height: Int) {
            configureTransformRear(width, height)
        }

        override fun onSurfaceTextureDestroyed(texture: SurfaceTexture) = true

        override fun onSurfaceTextureUpdated(texture: SurfaceTexture) = Unit

    }

    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val stateCallbackFront = object : CameraDevice.StateCallback() {

        override fun onOpened(cameraDevice: CameraDevice) {
            cameraOpenCloseLockFront.release()
            this@CameraFragment.cameraDeviceFront = cameraDevice
            createCameraPreviewSessionFront()
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            cameraOpenCloseLockFront.release()
            cameraDevice.close()
            this@CameraFragment.cameraDeviceFront = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            onDisconnected(cameraDevice)
            this@CameraFragment.activity?.finish()
        }

    }

    /**
     * [CameraDevice.StateCallback] is called when [CameraDevice] changes its state.
     */
    private val stateCallbackRear = object : CameraDevice.StateCallback() {

        override fun onOpened(cameraDevice: CameraDevice) {
            cameraOpenCloseLockRear.release()
            this@CameraFragment.cameraDeviceRear = cameraDevice
            createCameraPreviewSessionRear()
        }

        override fun onDisconnected(cameraDevice: CameraDevice) {
            cameraOpenCloseLockRear.release()
            cameraDevice.close()
            this@CameraFragment.cameraDeviceRear = null
        }

        override fun onError(cameraDevice: CameraDevice, error: Int) {
            onDisconnected(cameraDevice)
            this@CameraFragment.activity?.finish()
        }

    }

    override fun onCreateView(
        inflater: LayoutInflater, container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View? {
        // Inflate the layout for this fragment
        return inflater.inflate(R.layout.fragment_camera, container, false)
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        textureViewFront = view.findViewById(R.id.texture1)
        textureViewRear = view.findViewById(R.id.texture2)
    }

    override fun onResume() {
        super.onResume()
        startBackgroundThread()
        // When the screen is turned off and turned back on, the SurfaceTexture is already
        // available, and "onSurfaceTextureAvailable" will not be called. In that case, we can open
        // a camera and start preview from here (otherwise, we wait until the surface is ready in
        // the SurfaceTextureListener).
        if (textureViewFront.isAvailable) {
            openCameraFront(textureViewFront.width, textureViewFront.height)
        } else {
            textureViewFront.surfaceTextureListener = surfaceTextureListenerFront
        }
        if (textureViewRear.isAvailable) {
            openCameraRear(textureViewRear.width, textureViewRear.height)
        } else {
            textureViewRear.surfaceTextureListener = surfaceTextureListenerRear
        }
        fusedLocationClient = LocationServices.getFusedLocationProviderClient(requireActivity())
    }

    override fun onPause() {
        closeCameraFront()
        closeCameraRear()
        stopBackgroundThread()
        super.onPause()
    }


    /**
     * Opens front camera specified by [Camera2BasicFragment.cameraId].
     */
    private fun openCameraFront(width: Int, height: Int) {
        Log.d(TAG, "openCameraFront")
        val permission = activity?.let { ContextCompat.checkSelfPermission(it, Manifest.permission.CAMERA) }
        if (permission != PackageManager.PERMISSION_GRANTED) {
            requestMultiplePermissions()
            return
        }
        setUpCameraOutputsFront(width, height)
        configureTransformFront(width, height)
        val manager = activity?.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            // Wait for camera to open - 2.5 seconds is sufficient
            if (!cameraOpenCloseLockFront.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            manager.openCamera(cameraIdFront, stateCallbackFront, backgroundHandlerRear)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }
    }



    /**
     * Opens rear camera specified by [Camera2BasicFragment.cameraId].
     */
    private fun openCameraRear(width: Int, height: Int) {
        val permission = activity?.let { ContextCompat.checkSelfPermission(it, Manifest.permission.CAMERA) }
        if (permission != PackageManager.PERMISSION_GRANTED) {
            requestMultiplePermissions()
            return
        }
        setUpCameraOutputsRear(width, height)
        configureTransformRear(width, height)
        val manager = activity?.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            // Wait for camera to open - 2.5 seconds is sufficient
            if (!cameraOpenCloseLockRear.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            manager.openCamera(cameraIdRear, stateCallbackRear, backgroundHandlerRear)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }

    }


    private fun requestMultiplePermissions() {
        val requiredPermissions = arrayOf(
            Manifest.permission.WRITE_EXTERNAL_STORAGE,
            Manifest.permission.READ_EXTERNAL_STORAGE,
            Manifest.permission.ACCESS_FINE_LOCATION,
            Manifest.permission.CAMERA
        )

        val permissionsToRequest = mutableListOf<String>()
        requiredPermissions.forEach { permission ->
            if (ContextCompat.checkSelfPermission(requireActivity(), permission) != PackageManager.PERMISSION_GRANTED) {
                permissionsToRequest.add(permission)
            }
        }

        if (permissionsToRequest.isNotEmpty()) {
            // 필요한 권한들에 대해서 요청을 수행합니다.
            requestPermissions(permissionsToRequest.toTypedArray(), MULTIPLE_PERMISSIONS_REQUEST_CODE)
        } else {
            // 모든 필요한 권한이 이미 부여되었습니다. 다음 단계를 진행하세요.
        }
    }

    /**
     * Sets up member variables related to front camera.
     *
     * @param width  The width of available size for camera preview
     * @param height The height of available size for camera preview
     */
    private fun setUpCameraOutputsFront(width: Int, height: Int) {
        val manager = activity?.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            for (cameraId in manager.cameraIdList) {
                val characteristics = manager.getCameraCharacteristics(cameraId)

                // We don't use a front facing camera in this sample.
                val cameraDirection = characteristics.get(CameraCharacteristics.LENS_FACING)
                if (cameraDirection != null &&
                    cameraDirection == CameraCharacteristics.LENS_FACING_BACK) {
                    continue
                }

                val map = characteristics.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP) ?: continue

                // For still image captures, we use the largest available size.
                val aspectRatio = Collections.max(
                    Arrays.asList(*map.getOutputSizes(ImageFormat.JPEG)),
                    CompareSizesByViewAspectRatio(textureViewFront.height, textureViewFront.width))
                imageReaderFront = ImageReader.newInstance(aspectRatio.width, aspectRatio.height, ImageFormat.JPEG, 2).apply {
                    setOnImageAvailableListener(onImageAvailableListenerFront, backgroundHandlerFront)
                }


                Log.d(TAG, "selected aspect ratio " + aspectRatio.height  + "x" + aspectRatio.width + " : " + aspectRatio.height/aspectRatio.width)
                // Find out if we need to swap dimension to get the preview size relative to sensor
                // coordinate.
                val displayRotation = activity!!.windowManager.defaultDisplay.rotation

                sensorOrientationFront = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)!!
                val swappedDimensions = areDimensionsSwappedFront(displayRotation)

                val displaySize = Point()
                activity!!.windowManager.defaultDisplay.getSize(displaySize)
                val rotatedPreviewWidth = if (swappedDimensions) height else width
                val rotatedPreviewHeight = if (swappedDimensions) width else height
                var maxPreviewWidth = if (swappedDimensions) displaySize.y else displaySize.x
                var maxPreviewHeight = if (swappedDimensions) displaySize.x else displaySize.y

                if (maxPreviewWidth > MAX_PREVIEW_WIDTH) maxPreviewWidth = MAX_PREVIEW_WIDTH
                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) maxPreviewHeight = MAX_PREVIEW_HEIGHT

                // Danger, W.R.! Attempting to use too large a preview size could exceed the camera
                // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
                // garbage capture data.
                previewSizeFront = chooseOptimalSize(map.getOutputSizes(SurfaceTexture::class.java),
                    rotatedPreviewWidth, rotatedPreviewHeight,
                    maxPreviewWidth, maxPreviewHeight,
                    aspectRatio)


                /*
                 * We are filling the whole view with camera preview, on a downside, this distorts
                 * the aspect ratio.
                 * To retain the aspect ratio, uncomment the below line.
                 * Another option is the crop preview into the view, for that we have to choose
                 * preview ratio such that it comes nearest to aspect ratio of view.
                 */
//                if (resources.configuration.orientation == Configuration.ORIENTATION_PORTRAIT) {
//                    textureView.setAspectRatio(previewSize.width, previewSize.height)
//                } else {
//                    textureView.setAspectRatio(previewSize.height, previewSize.width)
//                }

                this.cameraIdFront = cameraId

                // We've found a viable camera and finished setting up member variables,
                // so we don't need to iterate through other available cameras.
                return
            }
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        } catch (e: NullPointerException) {
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
            // device this code runs.
            ErrorDialog.newInstance(getString(R.string.camera_error))
                .show(childFragmentManager, FRAGMENT_DIALOG)
        }

    }

    /**
     * Closes the current [CameraDevice].
     */
    private fun closeCameraFront() {
        try {
            if (Build.VERSION.SDK_INT <= Build.VERSION_CODES.N) {
                captureSessionFront?.stopRepeating();
                captureSessionFront?.abortCaptures();
            }

            cameraOpenCloseLockFront.acquire()
            captureSessionFront?.close()
            captureSessionFront = null
            cameraDeviceFront?.close()
            cameraDeviceFront = null
            imageReaderFront?.close()
            imageReaderFront = null



        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock front camera closing.", e)
        } finally {
            cameraOpenCloseLockFront.release()
        }
    }

    /**
     * Closes the current [CameraDevice].
     */
    private fun closeCameraRear() {
        try {
            if (Build.VERSION.SDK_INT <= Build.VERSION_CODES.N) {
                captureSessionRear?.stopRepeating();
                captureSessionRear?.abortCaptures();
            }
            cameraOpenCloseLockRear.acquire()
            captureSessionRear?.close()
            captureSessionRear = null
            cameraDeviceRear?.close()
            cameraDeviceRear = null
            imageReaderRear?.close()
            imageReaderRear = null
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock rear camera closing.", e)
        } finally {
            cameraOpenCloseLockRear.release()
        }
    }
    /**
     * Sets up member variables related to rear camera.
     *
     * @param width  The width of available size for camera preview
     * @param height The height of available size for camera preview
     */
    private fun setUpCameraOutputsRear(width: Int, height: Int) {
        val manager = activity?.getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            for (cameraId in manager.cameraIdList) {
                val characteristics = manager.getCameraCharacteristics(cameraId)

                // We don't use a front facing camera in this sample.
                val cameraDirection = characteristics.get(CameraCharacteristics.LENS_FACING)
                if (cameraDirection != null &&
                    cameraDirection == CameraCharacteristics.LENS_FACING_FRONT) {
                    continue
                }

                val map = characteristics.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP) ?: continue

                // For still image captures, we use the largest available size.
                val aspectRatio = Collections.max(
                    Arrays.asList(*map.getOutputSizes(ImageFormat.JPEG)),
                    CompareSizesByViewAspectRatio(textureViewRear.height, textureViewRear.width))
                imageReaderRear = ImageReader.newInstance(aspectRatio.width, aspectRatio.height,
                    ImageFormat.JPEG, /*maxImages*/ 2).apply {
                    setOnImageAvailableListener(onImageAvailableListenerRear, backgroundHandlerRear)
                }

                Log.d(TAG, "selected aspect ratio " + aspectRatio.height  + "x" + aspectRatio.width + " : " + aspectRatio.height/aspectRatio.width)
                // Find out if we need to swap dimension to get the preview size relative to sensor
                // coordinate.
                val displayRotation = activity!!.windowManager.defaultDisplay.rotation

                sensorOrientationRear = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION)!!
                val swappedDimensions = areDimensionsSwappedRear(displayRotation)

                val displaySize = Point()
                activity!!.windowManager.defaultDisplay.getSize(displaySize)
                val rotatedPreviewWidth = if (swappedDimensions) height else width
                val rotatedPreviewHeight = if (swappedDimensions) width else height
                var maxPreviewWidth = if (swappedDimensions) displaySize.y else displaySize.x
                var maxPreviewHeight = if (swappedDimensions) displaySize.x else displaySize.y

                if (maxPreviewWidth > MAX_PREVIEW_WIDTH) maxPreviewWidth = MAX_PREVIEW_WIDTH
                if (maxPreviewHeight > MAX_PREVIEW_HEIGHT) maxPreviewHeight = MAX_PREVIEW_HEIGHT

                // Danger, W.R.! Attempting to use too large a preview size could exceed the camera
                // bus' bandwidth limitation, resulting in gorgeous previews but the storage of
                // garbage capture data.
                previewSizeRear = chooseOptimalSize(map.getOutputSizes(SurfaceTexture::class.java),
                    rotatedPreviewWidth, rotatedPreviewHeight,
                    maxPreviewWidth, maxPreviewHeight,
                    aspectRatio)


                /*
                 * We are filling the whole view with camera preview, on a downside, this distorts
                 * the aspect ratio.
                 * To retain the aspect ratio, uncomment the below line.
                 * Another option is the crop preview into the view, for that we have to choose
                 * preview ratio such that it comes nearest to aspect ratio of view.
                 */
//                if (resources.configuration.orientation == Configuration.ORIENTATION_PORTRAIT) {
//                    textureView.setAspectRatio(previewSize.width, previewSize.height)
//                } else {
//                    textureView.setAspectRatio(previewSize.height, previewSize.width)
//                }

                this.cameraIdRear = cameraId

                // We've found a viable camera and finished setting up member variables,
                // so we don't need to iterate through other available cameras.
                return
            }
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        } catch (e: NullPointerException) {
            // Currently an NPE is thrown when the Camera2API is used but not supported on the
            // device this code runs.
            ErrorDialog.newInstance(getString(R.string.camera_error))
                .show(childFragmentManager, FRAGMENT_DIALOG)
        }

    }



    /**
     * Configures the necessary [android.graphics.Matrix] transformation to `textureView`.
     * This method should be called after the camera preview size is determined in
     * setUpCameraOutputs and also the size of `textureView` is fixed.
     *
     * @param viewWidth  The width of `textureView`
     * @param viewHeight The height of `textureView`
     */
    private fun configureTransformFront(viewWidth: Int, viewHeight: Int) {
        activity ?: return
        val rotation = activity!!.windowManager.defaultDisplay.rotation
        val matrix = Matrix()
        val viewRect = RectF(0f, 0f, viewWidth.toFloat(), viewHeight.toFloat())
        val bufferRect = RectF(0f, 0f, previewSizeFront.height.toFloat(), previewSizeFront.width.toFloat())
        val centerX = viewRect.centerX()
        val centerY = viewRect.centerY()

        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
            bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
            val scale = Math.max(
                viewHeight.toFloat() / previewSizeFront.height,
                viewWidth.toFloat() / previewSizeFront.width)
            with(matrix) {
                setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
                postScale(scale, scale, centerX, centerY)
                postRotate((90 * (rotation - 2)).toFloat(), centerX, centerY)
            }
        } else if (Surface.ROTATION_180 == rotation) {
            matrix.postRotate(180f, centerX, centerY)
        }
        textureViewFront.setTransform(matrix)
    }

    /**
     * Configures the necessary [android.graphics.Matrix] transformation to `textureView`.
     * This method should be called after the camera preview size is determined in
     * setUpCameraOutputs and also the size of `textureView` is fixed.
     *
     * @param viewWidth  The width of `textureView`
     * @param viewHeight The height of `textureView`
     */
    private fun configureTransformRear(viewWidth: Int, viewHeight: Int) {
        activity ?: return
        val rotation = activity!!.windowManager.defaultDisplay.rotation
        val matrix = Matrix()
        val viewRect = RectF(0f, 0f, viewWidth.toFloat(), viewHeight.toFloat())
        val bufferRect = RectF(0f, 0f, previewSizeRear.height.toFloat(), previewSizeRear.width.toFloat())
        val centerX = viewRect.centerX()
        val centerY = viewRect.centerY()

        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
            bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY())
            val scale = Math.max(
                viewHeight.toFloat() / previewSizeRear.height,
                viewWidth.toFloat() / previewSizeRear.width)
            with(matrix) {
                setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL)
                postScale(scale, scale, centerX, centerY)
                postRotate((90 * (rotation - 2)).toFloat(), centerX, centerY)
            }
        } else if (Surface.ROTATION_180 == rotation) {
            matrix.postRotate(180f, centerX, centerY)
        }
        textureViewRear.setTransform(matrix)
    }

    /**
     * Determines if the dimensions are swapped given the phone's current rotation.
     *
     * @param displayRotation The current rotation of the display
     *
     * @return true if the dimensions are swapped, false otherwise.
     */
    private fun areDimensionsSwappedFront(displayRotation: Int): Boolean {
        var swappedDimensions = false
        when (displayRotation) {
            Surface.ROTATION_0, Surface.ROTATION_180 -> {
                if (sensorOrientationFront == 90 || sensorOrientationFront == 270) {
                    swappedDimensions = true
                }
            }
            Surface.ROTATION_90, Surface.ROTATION_270 -> {
                if (sensorOrientationFront == 0 || sensorOrientationFront == 180) {
                    swappedDimensions = true
                }
            }
            else -> {
                Log.e(TAG, "Display rotation is invalid: $displayRotation")
            }
        }
        return swappedDimensions
    }


    /**
     * Determines if the dimensions are swapped given the phone's current rotation.
     *
     * @param displayRotation The current rotation of the display
     *
     * @return true if the dimensions are swapped, false otherwise.
     */
    private fun areDimensionsSwappedRear(displayRotation: Int): Boolean {
        var swappedDimensions = false
        when (displayRotation) {
            Surface.ROTATION_0, Surface.ROTATION_180 -> {
                if (sensorOrientationRear == 90 || sensorOrientationRear == 270) {
                    swappedDimensions = true
                }
            }
            Surface.ROTATION_90, Surface.ROTATION_270 -> {
                if (sensorOrientationRear == 0 || sensorOrientationRear == 180) {
                    swappedDimensions = true
                }
            }
            else -> {
                Log.e(TAG, "Display rotation is invalid: $displayRotation")
            }
        }
        return swappedDimensions
    }

    /**
     * Starts a background thread and its [Handler].
     */
    private fun startBackgroundThread() {
        backgroundThreadFront = HandlerThread("CameraBackgroundFront").also { it.start() }
        backgroundThreadRear = HandlerThread("CameraBackgroundRear").also { it.start() }

        backgroundHandlerFront = Handler(backgroundThreadFront?.looper)
        backgroundHandlerRear = Handler(backgroundThreadRear?.looper)
    }

    /**
     * Stops the background thread and its [Handler].
     */
    private fun stopBackgroundThread() {
        backgroundThreadFront?.quitSafely()
        backgroundThreadRear?.quitSafely()


        try {
            backgroundThreadFront?.join()
            backgroundThreadFront = null
            backgroundHandlerFront = null

            backgroundThreadRear?.join()
            backgroundThreadRear = null
            backgroundHandlerRear = null


        } catch (e: InterruptedException) {
            Log.e(TAG, e.toString())
        }

    }

    /**
     * Creates a new [CameraCaptureSession] for front camera preview.
     */
    private fun createCameraPreviewSessionFront() {
        try {
            val texture = textureViewFront.surfaceTexture

            // We configure the size of default buffer to be the size of camera preview we want.
            texture.setDefaultBufferSize(previewSizeFront.width, previewSizeFront.height)

            // This is the output Surface we need to start preview.
            val surface = Surface(texture)

            // We set up a CaptureRequest.Builder with the output Surface.
            previewRequestBuilderFront = cameraDeviceFront!!.createCaptureRequest(
                CameraDevice.TEMPLATE_PREVIEW
            )
            previewRequestBuilderFront.addTarget(surface)
            previewRequestBuilderFront.addTarget(imageReaderFront!!.surface)

            // Here, we create a CameraCaptureSession for camera preview.
            cameraDeviceFront?.createCaptureSession(Arrays.asList(surface, imageReaderFront?.surface),
                object : CameraCaptureSession.StateCallback() {

                    override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                        // The camera is already closed
                        if (cameraDeviceFront == null) return

                        // When the session is ready, we start displaying the preview.
                        captureSessionFront = cameraCaptureSession
                        try {
                            // Auto focus should be continuous for camera preview.
                            previewRequestBuilderFront.set(CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE)

                            // Finally, we start displaying the camera preview.
                            previewRequestFront = previewRequestBuilderFront.build()
                            captureSessionFront?.setRepeatingRequest(previewRequestFront,
                                captureCallback, backgroundHandlerFront)
                        } catch (e: CameraAccessException) {
                            Log.e(TAG, e.toString())
                        }

                    }

                    override fun onConfigureFailed(session: CameraCaptureSession) {
                        Log.d(TAG, "CaptureSession failed")
                    }
                }, null)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        }

    }

    /**
     * Creates a new [CameraCaptureSession] for rear camera preview.
     */
    private fun createCameraPreviewSessionRear() {
        try {
            val texture = textureViewRear.surfaceTexture

            // We configure the size of default buffer to be the size of camera preview we want.
            texture.setDefaultBufferSize(previewSizeRear.width, previewSizeRear.height)

            // This is the output Surface we need to start preview.
            val surface = Surface(texture)

            // We set up a CaptureRequest.Builder with the output Surface.
            previewRequestBuilderRear = cameraDeviceRear!!.createCaptureRequest(
                CameraDevice.TEMPLATE_PREVIEW
            )
            previewRequestBuilderRear.addTarget(surface)
            previewRequestBuilderRear.addTarget(imageReaderRear!!.surface)

            // Here, we create a CameraCaptureSession for camera preview.
            cameraDeviceRear?.createCaptureSession(Arrays.asList(surface, imageReaderRear?.surface),
                object : CameraCaptureSession.StateCallback() {

                    override fun onConfigured(cameraCaptureSession: CameraCaptureSession) {
                        // The camera is already closed
                        if (cameraDeviceRear == null) return

                        // When the session is ready, we start displaying the preview.
                        captureSessionRear = cameraCaptureSession
                        try {
                            // Auto focus should be continuous for camera preview.
                            previewRequestBuilderRear.set(CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE)

                            // Finally, we start displaying the camera preview.
                            previewRequestRear = previewRequestBuilderRear.build()
                            captureSessionRear?.setRepeatingRequest(previewRequestRear,
                                captureCallback, backgroundHandlerRear)
                        } catch (e: CameraAccessException) {
                            Log.e(TAG, e.toString())
                        }

                    }

                    override fun onConfigureFailed(session: CameraCaptureSession) {
//                        activity.showToast("Failed")
                        Log.d(TAG, "CaptureSession failed")
                    }
                }, null)
        } catch (e: CameraAccessException) {
            Log.e(TAG, e.toString())
        }

    }


    companion object {

        /**
         * Conversion from screen rotation to JPEG orientation.
         */
        private val ORIENTATIONS = SparseIntArray()
        private val FRAGMENT_DIALOG = "dialog"

        init {
            ORIENTATIONS.append(Surface.ROTATION_0, 90)
            ORIENTATIONS.append(Surface.ROTATION_90, 0)
            ORIENTATIONS.append(Surface.ROTATION_180, 270)
            ORIENTATIONS.append(Surface.ROTATION_270, 180)
        }

        /**
         * Max preview width that is guaranteed by Camera2 API
         */
        private val MAX_PREVIEW_WIDTH = 1920

        /**
         * Max preview height that is guaranteed by Camera2 API
         */
        private val MAX_PREVIEW_HEIGHT = 1080


        /**
         * Given `choices` of `Size`s supported by a camera, choose the smallest one that
         * is at least as large as the respective texture view size, and that is at most as large as
         * the respective max size, and whose aspect ratio matches with the specified value. If such
         * size doesn't exist, choose the largest one that is at most as large as the respective max
         * size, and whose aspect ratio matches with the specified value.
         *
         * @param choices           The list of sizes that the camera supports for the intended
         *                          output class
         * @param textureViewWidth  The width of the texture view relative to sensor coordinate
         * @param textureViewHeight The height of the texture view relative to sensor coordinate
         * @param maxWidth          The maximum width that can be chosen
         * @param maxHeight         The maximum height that can be chosen
         * @param aspectRatio       The aspect ratio
         * @return The optimal `Size`, or an arbitrary one if none were big enough
         */
        @JvmStatic private fun chooseOptimalSize(
            choices: Array<Size>,
            textureViewWidth: Int,
            textureViewHeight: Int,
            maxWidth: Int,
            maxHeight: Int,
            aspectRatio: Size
        ): Size {

            // Collect the supported resolutions that are at least as big as the preview Surface
            val bigEnough = ArrayList<Size>()
            // Collect the supported resolutions that are smaller than the preview Surface
            val notBigEnough = ArrayList<Size>()
            val w = aspectRatio.width
            val h = aspectRatio.height
            for (option in choices) {
                if (option.width <= maxWidth && option.height <= maxHeight &&
                    option.height == option.width * h / w) {
                    if (option.width >= textureViewWidth && option.height >= textureViewHeight) {
                        bigEnough.add(option)
                    } else {
                        notBigEnough.add(option)
                    }
                }
            }

            // Pick the smallest of those big enough. If there is no one big enough, pick the
            // largest of those not big enough.
            if (bigEnough.size > 0) {
                return Collections.min(bigEnough, CompareSizesByViewAspectRatio(textureViewHeight, textureViewWidth))
            } else if (notBigEnough.size > 0) {
                return Collections.max(notBigEnough, CompareSizesByViewAspectRatio(textureViewHeight, textureViewWidth))
            } else {
                Log.e(TAG, "Couldn't find any suitable preview size")
                return choices[0]
            }
        }

        /**
         * Tag for the [Log] from this class
         */
        private val TAG = CameraFragment::class.java.simpleName

        @JvmStatic fun newInstance(): CameraFragment = CameraFragment()
    }

}
